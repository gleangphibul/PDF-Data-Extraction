{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/UyBYjunEOOLxyIVmRbi6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gleangphibul/PDF-Data-Extraction/blob/main/PDFTextExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup**"
      ],
      "metadata": {
        "id": "BlY72I1HT036"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For troubleshooting (no need to run)\n",
        "\n",
        "# !pip uninstall pdfminer.six pdfminer -y\n",
        "\n",
        "# !pip uninstall ocrmypdf pikepdf -y"
      ],
      "metadata": {
        "id": "DtqWygRpr4DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fwbp7wKunL2V",
        "outputId": "1a40b60e-1d06-4341-e8fa-a31950961d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pikepdf==10.0.2 in /usr/local/lib/python3.12/dist-packages (10.0.2)\n",
            "Requirement already satisfied: Pillow>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from pikepdf==10.0.2) (11.3.0)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.12/dist-packages (from pikepdf==10.0.2) (1.3.1)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.12/dist-packages (from pikepdf==10.0.2) (6.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pikepdf==10.0.2) (26.0)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->pikepdf==10.0.2) (2.1.1)\n",
            "Requirement already satisfied: ocrmypdf in /usr/local/lib/python3.12/dist-packages (17.2.0)\n",
            "Requirement already satisfied: deprecation>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (2.1.0)\n",
            "Requirement already satisfied: fpdf2>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (2.8.5)\n",
            "Requirement already satisfied: img2pdf>=0.5 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (0.6.3)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (26.0)\n",
            "Requirement already satisfied: pdfminer-six>=20220319 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (20260107)\n",
            "Requirement already satisfied: pi-heif in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (1.2.0)\n",
            "Requirement already satisfied: pikepdf>=10 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (10.0.2)\n",
            "Requirement already satisfied: pillow>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (11.3.0)\n",
            "Requirement already satisfied: pluggy>=1 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.12.5 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (2.12.5)\n",
            "Requirement already satisfied: pypdfium2>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (5.4.0)\n",
            "Requirement already satisfied: rich>=13 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (13.9.4)\n",
            "Requirement already satisfied: uharfbuzz>=0.53.2 in /usr/local/lib/python3.12/dist-packages (from ocrmypdf) (0.53.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from fpdf2>=2.8.0->ocrmypdf) (0.7.1)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from fpdf2>=2.8.0->ocrmypdf) (4.61.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20220319->ocrmypdf) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20220319->ocrmypdf) (43.0.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.12/dist-packages (from pikepdf>=10->ocrmypdf) (1.3.1)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.12/dist-packages (from pikepdf>=10->ocrmypdf) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.5->ocrmypdf) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.5->ocrmypdf) (2.41.5)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.5->ocrmypdf) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.5->ocrmypdf) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13->ocrmypdf) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13->ocrmypdf) (2.19.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20220319->ocrmypdf) (2.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13->ocrmypdf) (0.1.2)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->pikepdf>=10->ocrmypdf) (2.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20220319->ocrmypdf) (3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (26.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (11.3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ghostscript is already the newest version (9.55.0~dfsg1-0ubuntu5.13).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n",
            "Requirement already satisfied: tabula-py in /usr/local/lib/python3.12/dist-packages (2.10.0)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.12/dist-packages (from tabula-py) (2.2.2)\n",
            "Requirement already satisfied: numpy>1.24.4 in /usr/local/lib/python3.12/dist-packages (from tabula-py) (2.0.2)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.12/dist-packages (from tabula-py) (1.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25.3->tabula-py) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.17.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:3 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 3,917 B in 1s (3,733 B/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openjdk-11-jdk-headless is already the newest version (11.0.30+7-1ubuntu1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 63 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages (Run Once)\n",
        "\n",
        "!pip install pikepdf==10.0.2\n",
        "!pip install ocrmypdf\n",
        "!pip install PyMuPDF -q\n",
        "\n",
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "\n",
        "!pip install pytesseract\n",
        "!apt install ghostscript\n",
        "\n",
        "!pip install tabula-py\n",
        "\n",
        "!pip install PyPDF2\n",
        "\n",
        "# Install Java (Needed for table extraction library)\n",
        "!apt-get update\n",
        "!apt-get install -y openjdk-11-jdk-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First finish setting up Java\n",
        "\n",
        "# Set JAVA_HOME environment variable\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "\n",
        "# Verify installation\n",
        "!java -version"
      ],
      "metadata": {
        "id": "-7N6HU6WsbXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def1aefb-0d62-4684-f2d6-1fbd88f5829f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"17.0.17\" 2025-10-21\n",
            "OpenJDK Runtime Environment (build 17.0.17+10-Ubuntu-122.04)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.17+10-Ubuntu-122.04, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then import other packages\n",
        "\n",
        "# General quality of life libraries\n",
        "import requests # for general processes\n",
        "import subprocess # used to run ocrmypdf\n",
        "import shutil # used to replace original file with ocr-ed file\n",
        "import pandas as pd # for data frame data structure, used for easy conversion to excel\n",
        "import numpy as np # allows operations such as rounding\n",
        "import re # Allows regular expressions, used for finding the last page of a table\n",
        "\n",
        "import ocrmypdf # for optical character recognition\n",
        "\n",
        "import pymupdf # used to extract text from pdf\n",
        "import fitz # dependency for pymupdf\n",
        "\n",
        "import tabula # used to extract tables\n",
        "\n",
        "import PyPDF2 # For PDF reading and manipulation (e.g. count number of pages)\n",
        "\n",
        "\n",
        "from google.colab import drive # To access files stored on google drive"
      ],
      "metadata": {
        "id": "yFyg6fyGnUxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to Google Drive (gives code access to files in Google Drive)\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "G5z1jyJ3tutq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2d6e8c-878f-4f0e-f6c2-19f7e7a42b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "General Helper Methods"
      ],
      "metadata": {
        "id": "0XGl99kaUQT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Takes a dataframe data structure and exports it to a csv file\n",
        "# Stores it in whatever file path specified (currently a google drive folder)\n",
        "# Inputs: df <-- the dataframe, name <-- what you want to name the file\n",
        "def export_file_to_csv(df, name):\n",
        "\n",
        "  print(\"Running export_file_to_csv()\")\n",
        "\n",
        "  root_store_path = '/content/drive/My Drive/PDF_Text_Extraction_Project/Excel_Tables'\n",
        "  store_path = os.path.join(root_store_path, f\"{name}.csv\")\n",
        "\n",
        "  df.to_csv(store_path)"
      ],
      "metadata": {
        "id": "pf7ykuImsbJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Approval Form PDFs**"
      ],
      "metadata": {
        "id": "n9bi5CTrTQxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixes the misprocessing where first row becomes column names\n",
        "# Grabs the first row data from the column names and make it a mergable row\n",
        "# Then, return the row\n",
        "def get_first_row(df):\n",
        "  print(\"Running get_first_row()\")\n",
        "\n",
        "  # Create the first row as a list: the name, followed by empty cells\n",
        "  first_row = [df.columns[0]]\n",
        "  first_row.extend([\"\"] * (df.shape[1] - 1))\n",
        "\n",
        "  # Turn it into a mergable row (dataframe type)\n",
        "  first_row_df = pd.DataFrame([first_row], columns=df.columns)\n",
        "\n",
        "  return first_row_df\n"
      ],
      "metadata": {
        "id": "36pGcIYF5yAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix second row to repeat values for subcells.\n",
        "# Ex: Recruiting Agency, Recruiting Agency, Recruiting agency, Individual-New, ...\n",
        "# Then, returns the row\n",
        "def get_second_row(df):\n",
        "\n",
        "  print(\"Running get_second_row()\")\n",
        "  print(\"Dataframe size:\", df.shape)\n",
        "\n",
        "  # Copy the values over from the second row\n",
        "  second_row_copy = df.iloc[0]\n",
        "\n",
        "  # Drop 'nan' values\n",
        "  cleaned_second_row = second_row_copy.dropna()\n",
        "\n",
        "  # Create the second row as a list\n",
        "  second_row_data = cleaned_second_row.tolist()\n",
        "  print(second_row_data) # Debugging statement\n",
        "\n",
        "  # List form of the second row\n",
        "  second_row_list = [\"\", \"\"]\n",
        "\n",
        "  # Get each cell value in the original second row and write it 3 times\n",
        "  # in the new second row (this one will replace the original second row)\n",
        "  for value in second_row_data:\n",
        "    second_row_list.extend([value] * 3)\n",
        "    #second_row_list.extend([\"\"]) # Temp line of code: ensure column sizes match\n",
        "\n",
        "  while len(second_row_list) < df.shape[1]:\n",
        "    second_row_list.extend([\"\"])\n",
        "\n",
        "  print(\"Length of second_row_list:\", len(second_row_list))\n",
        "\n",
        "  # Turn the list back into a dataframe\n",
        "  second_row_df = pd.DataFrame([second_row_list], columns=df.columns)\n",
        "\n",
        "  return second_row_df"
      ],
      "metadata": {
        "id": "lpHccoVAjxNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loops through a list of dataframes and checks for a last page\n",
        "# using conditions where designated position is either: empty, 'Total', or numeric data\n",
        "# inputs: a list of dataframes, a start page\n",
        "def blind_find_last_page(dfs, start_page):\n",
        "\n",
        "\n",
        "  page = start_page\n",
        "\n",
        "  integer_regex = '[0-9]+'  # regular expression for any integer\n",
        "\n",
        "\n",
        "  for i in range(len(dfs)):\n",
        "    temp_df = dfs[i]\n",
        "    pos1 = temp_df.iloc[-1, 0] # Last row, first column\n",
        "    pos2 = temp_df.iloc[-1, 1] # Last row, second column\n",
        "    empty_cell = pd.isna(pos1)\n",
        "\n",
        "    # Converting data to string type to allow use of regular expressions\n",
        "    if hasattr(pos2, 'decode'):\n",
        "      pos2 = pos2.decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "      pos2 = str(pos2)\n",
        "    try:\n",
        "      matched_regex = re.search(integer_regex, pos2)\n",
        "    except:\n",
        "      print(\"Could not use regular expression in blind_find_last_page\")\n",
        "\n",
        "    # Found the last page if the last row, first column either says 'Total' or is empty\n",
        "    # Or, last row, second column displays data (integers) instead of a country name (string)\n",
        "    if empty_cell or pos1 == \"Total\" or matched_regex:\n",
        "      print(\"blind_find_last_page() ran successfully\")\n",
        "      return page\n",
        "    page += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "u-Wrb2KQP_Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually calculates the total row by summing all the columns\n",
        "# of a dataframe\n",
        "# Input: a list of dataframes (each element represents a page)\n",
        "def calculate_total_row(dfs):\n",
        "  print(\"calculating total row, length of dfs is\", len(dfs))\n",
        "\n",
        "  # One page only\n",
        "  if len(dfs) == 1:\n",
        "    print(\"just one page\")\n",
        "    # First create a dataframe with only numerical values,\n",
        "    # ready for the sum to be calculated\n",
        "    df_list = []\n",
        "\n",
        "    # Grab the rows with values only, ignoring rows that are just column titles\n",
        "    # Also ignore the last row which is the total column\n",
        "    first_df = dfs[0]\n",
        "    temp_first_df = first_df[2:-1]\n",
        "    temp_first_df.columns = range(len(temp_first_df.columns)) # Setting column names to default to avoid append conflicts\n",
        "    df_list.append(temp_first_df)\n",
        "\n",
        "  # More than one page\n",
        "  else:\n",
        "    print(\"more than one page\")\n",
        "    # First create a dataframe with only numerical values,\n",
        "    # ready for the sum to be calculated\n",
        "    df_list = []\n",
        "\n",
        "    # Grab the rows with values only, ignoring rows that are just column titles\n",
        "    first_df = dfs[0]\n",
        "    temp_first_df = first_df[2:]\n",
        "    temp_first_df.columns = range(len(temp_first_df.columns)) # Setting column names to default to avoid append conflicts\n",
        "\n",
        "    df_list.append(temp_first_df)\n",
        "\n",
        "    # For the middle pages, set the column names to default to avoid append conflicts\n",
        "    # Then add it to the list ready to be appended\n",
        "    for i in range(1, len(dfs) - 1):\n",
        "      print(\"loop ran. DFS more than one page\")\n",
        "      temp_df = dfs[i]\n",
        "      temp_df.columns = range(len(temp_df.columns))\n",
        "      df_list.append(temp_df)\n",
        "\n",
        "    # Do the same for the last page's dataframe\n",
        "    last_df = dfs[-1]\n",
        "    temp_last_df = last_df[:-1]\n",
        "    temp_last_df.columns = range(len(temp_last_df.columns))\n",
        "    df_list.append(temp_last_df)\n",
        "\n",
        "  temp_df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "  last_row_list = [\"\", \"Total\"]\n",
        "\n",
        "  # Now calculate the sum:\n",
        "  for i in range(len(temp_df.columns)):\n",
        "    # Third column or beyond (first two columns are id, countryname)\n",
        "    if i >= 2:\n",
        "      col_numeric = pd.to_numeric(temp_df.iloc[:, i], errors='coerce')\n",
        "      col_sum = col_numeric.sum()\n",
        "      floored_col_sum = np.floor(col_sum)\n",
        "      last_row_list.append(floored_col_sum)\n",
        "\n",
        "  # Convert list to a pandas dataframe\n",
        "  last_row_df = pd.DataFrame([last_row_list], columns=range(len(temp_first_df.columns)))\n",
        "\n",
        "  return last_row_df\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbfdTXwX2H-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For debugging\n",
        "def visualize_problematic_pdf(folder_path, file_i, start_p):\n",
        "\n",
        "  # First get the file\n",
        "  files = os.listdir(folder_path)\n",
        "  file = os.path.join(folder_path, files[file_i])\n",
        "\n",
        "  # Arbitrary range of 5 pages (can be modified whenever)\n",
        "  blind_start_page = start_p\n",
        "  blind_end_page = blind_start_page + 5\n",
        "\n",
        "  # Grab tables from an arbitrary page range\n",
        "  temp_dfs = tabula.read_pdf(file, lattice=True, pages=f'{blind_start_page}-{blind_end_page}', silent=True)\n",
        "\n",
        "  start_page = start_p\n",
        "  last_page = blind_find_last_page(temp_dfs, start_page)\n",
        "\n",
        "  # One page\n",
        "  if start_page == last_page:\n",
        "    print(\"one page\")\n",
        "    df = temp_dfs[0]\n",
        "    export_file_to_csv(df, \"Test\")\n",
        "    return df\n",
        "  # More than one page\n",
        "  else:\n",
        "    print(\"more than one page\")\n",
        "    page_length = last_page - start_page\n",
        "    dfs_list = temp_dfs[0:page_length+1]\n",
        "    for i in range(len(dfs_list)):\n",
        "      df = dfs_list[i]\n",
        "      export_file_to_csv(df, f'test{i}')\n",
        "    return dfs_list\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bmi25rQhVbFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resizing, removing extra column on the right\n",
        "def remove_extra_col(df):\n",
        "  new_df = df.drop(df.columns[-1], axis=1)\n",
        "  return new_df"
      ],
      "metadata": {
        "id": "xESf2xmoRRlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The main function for handling problematic pdfs: pdfs that threw errors in the main function\n",
        "\n",
        "def handle_problematic_pdf(folder_path, file_i, start_p):\n",
        "\n",
        "  print(\"handle_problematic_pdf() has started\")\n",
        "\n",
        "  # First get the file\n",
        "  files = os.listdir(folder_path)\n",
        "  file = os.path.join(folder_path, files[file_i])\n",
        "\n",
        "  # Arbitrary range of 5 pages (can be modified whenever)\n",
        "  blind_start_page = start_p\n",
        "  blind_end_page = blind_start_page + 5\n",
        "\n",
        "  # Grab tables from an arbitrary page range\n",
        "  temp_dfs = tabula.read_pdf(file, lattice=True, pages=f'{blind_start_page}-{blind_end_page}', silent=True)\n",
        "\n",
        "  start_page = start_p\n",
        "  last_page = blind_find_last_page(temp_dfs, start_page)\n",
        "\n",
        "  #print(\"last_page:\", last_page)\n",
        "\n",
        "  # Check if there is an extra column on the right\n",
        "  # If yes, remove it\n",
        "  dfs = []\n",
        "\n",
        "  #print(\"before:\", len(dfs))\n",
        "\n",
        "  for df in temp_dfs:\n",
        "    num_col = df.shape[1]\n",
        "    if num_col > 23:\n",
        "      #print(\"removed rightmost column\")\n",
        "      new_df = remove_extra_col(df)\n",
        "      dfs.append(new_df)\n",
        "    else:\n",
        "      #print(\"did not remove rightmost column\")\n",
        "      dfs.append(df)\n",
        "\n",
        "  #print(\"after:\", len(dfs))\n",
        "\n",
        "  # Debugging statement\n",
        "  #for df in dfs:\n",
        "    #print(dfs)\n",
        "    #print(df.shape[1])\n",
        "\n",
        "  # Only one page\n",
        "  if start_page == last_page:\n",
        "    print(\"only one page\")\n",
        "    one_page_list = []\n",
        "    one_page_list.append(dfs[0])\n",
        "    #print(type(one_page_list[0]))\n",
        "\n",
        "    first_row = get_first_row(one_page_list[0])\n",
        "    second_row = get_second_row(one_page_list[0])\n",
        "\n",
        "    # Last row alignment check\n",
        "    pos = one_page_list[0].iloc[-1,1] # Last row, second column\n",
        "\n",
        "    # Last row is misaligned, so realign it\n",
        "    if pos != 'Total':\n",
        "      print(\"last row is misaligned\")\n",
        "      print(one_page_list[0].shape)\n",
        "      last_row = calculate_total_row(one_page_list)\n",
        "      print(\"calculate_total_row() finished\")\n",
        "      remaining_first_table = one_page_list[0].iloc[1:-1]\n",
        "      df_append_list = [first_row, second_row, remaining_first_table, last_row]\n",
        "\n",
        "    # Last row is aligned perfectly, no changes needed\n",
        "    else:\n",
        "      print(\"last row is perfectly normal\")\n",
        "      remaining_first_table = one_page_list[0].iloc[1:]\n",
        "      df_append_list = [first_row, second_row, remaining_first_table]\n",
        "\n",
        "    # Standardize all df's column names to make sure appending occurs properly\n",
        "    df_append_list_fixed = []\n",
        "    for df in df_append_list:\n",
        "      print(type(df))\n",
        "      df_fixed = df.copy()\n",
        "      df_fixed.columns = range(len(df_fixed.columns))\n",
        "      df_append_list_fixed.append(df_fixed)\n",
        "\n",
        "    final_df = pd.concat(df_append_list_fixed, ignore_index=True)\n",
        "\n",
        "  # More than one page\n",
        "  else:\n",
        "    print(\"more than one page:\", last_page, \"pages\")\n",
        "\n",
        "    page_length = last_page - start_page\n",
        "    dfs_list = dfs[0:page_length+1]\n",
        "    print(\"Dataframes collected:\", len(dfs_list))\n",
        "\n",
        "    # Handle the first page first\n",
        "    first_row = get_first_row(dfs_list[0])\n",
        "    second_row = get_second_row(dfs_list[0])\n",
        "\n",
        "    remaining_first_table = dfs_list[0].iloc[1:]\n",
        "\n",
        "    total_row_calculate = [dfs_list[0]]\n",
        "\n",
        "    df_append_list = [first_row, second_row, remaining_first_table]\n",
        "\n",
        "    # Now handle all the pages up to the second last page\n",
        "    integer_regex = '[0-9]+' # Used to identify whether first rows are column headers or data\n",
        "\n",
        "    for i in range(1, len(dfs_list) - 1):\n",
        "      print(\"entered the for loop, count:\", i)\n",
        "\n",
        "      initial_df = dfs_list[i]\n",
        "\n",
        "      pos1 = initial_df.iloc[0, 2] # First row, second column\n",
        "\n",
        "      # Converting data to string type to allow use of regular expressions\n",
        "      if hasattr(pos1, 'decode'):\n",
        "        pos1 = pos1.decode('utf-8', errors='ignore')\n",
        "      else:\n",
        "        pos1 = str(pos1)\n",
        "\n",
        "      try:\n",
        "        first_row_is_data = re.search(integer_regex, pos1)\n",
        "      except:\n",
        "        print(\"could not use regex in handle_problematic_pdf()\")\n",
        "\n",
        "      # If first rows are column headers instead of data\n",
        "      # Grab only the data rows\n",
        "      if not first_row_is_data:\n",
        "        print(\"first row is not data, column headers!\")\n",
        "        df = initial_df.iloc[2:]\n",
        "\n",
        "        df_append_list.append(fixed_df)\n",
        "        total_row_calculate.append(fixed_df)\n",
        "      else:\n",
        "        print(\"first row is data\")\n",
        "        df = dfs_list[i]\n",
        "\n",
        "        # Here the first row accidentally gets treated as a header\n",
        "        # Fix this by grabbing data from the header and inserting it as\n",
        "        # the first row\n",
        "        header_data = df.columns.tolist()\n",
        "        header_df = pd.DataFrame([header_data], columns=df.columns) # Turn it back into a dataframe\n",
        "\n",
        "        fixed_df = pd.concat([header_df, df], ignore_index=True)\n",
        "\n",
        "        df_append_list.append(fixed_df)\n",
        "        total_row_calculate.append(fixed_df)\n",
        "\n",
        "    # For the last page\n",
        "    print(\"for loop finished running\")\n",
        "\n",
        "    initial_last_page = dfs_list[-1]\n",
        "    pos1 = initial_last_page.iloc[0, 2] # First row, second column\n",
        "\n",
        "    # Converting data to string type to allow use of regular expressions\n",
        "    if hasattr(pos1, 'decode'):\n",
        "      pos1 = pos1.decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "      pos1 = str(pos1)\n",
        "\n",
        "    first_row_is_data = re.search(integer_regex, pos1)\n",
        "\n",
        "    if not first_row_is_data:\n",
        "      print(\"first row is not data, column headers!\")\n",
        "      fixed_last_page = initial_last_page.iloc[2:]\n",
        "    else:\n",
        "      page_last = dfs_list[-1]\n",
        "\n",
        "      # First row was mistakenly taken as a column name so add that back into the dataframe\n",
        "      last_p_header_data = page_last.columns.tolist()\n",
        "      last_p_header_df = pd.DataFrame([last_p_header_data], columns=page_last.columns)\n",
        "\n",
        "      fixed_last_page = pd.concat([last_p_header_df, page_last], ignore_index=True)\n",
        "\n",
        "    last_page_upper = fixed_last_page.iloc[:-1]\n",
        "    df_append_list.append(last_page_upper)\n",
        "\n",
        "    total_row_calculate.append(fixed_last_page)\n",
        "\n",
        "    # Now for the last page, we need to manually calculate the total row ourselves\n",
        "    last_row = calculate_total_row(total_row_calculate)\n",
        "    #print(last_row)\n",
        "\n",
        "    df_append_list.append(last_row)\n",
        "\n",
        "    # Standardize all df's column names to make sure appending occurs properly\n",
        "    df_append_list_fixed = []\n",
        "    for df in df_append_list:\n",
        "      df_fixed = df.copy()\n",
        "      df_fixed.columns = range(len(df_fixed.columns))\n",
        "      df_append_list_fixed.append(df_fixed)\n",
        "\n",
        "    # Once everything (e.g. pages) is ordered correctly, append the separate dataframes\n",
        "    final_df = pd.concat(df_append_list_fixed, ignore_index=True)\n",
        "    #print(final_df)\n",
        "\n",
        "  print(\"handle_problematic_pdf() has finished running\")\n",
        "  #return final_df\n",
        "  return final_df, last_page\n"
      ],
      "metadata": {
        "id": "GbbG2hiESw3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Function"
      ],
      "metadata": {
        "id": "8sSbB15zRhnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop Function\n",
        "\n",
        "def get_approval_PDFs(folder_p):\n",
        "\n",
        "  # List of data frames to append later\n",
        "  country_dfs = []  # for countrywise\n",
        "  district_dfs = [] # for districtwise\n",
        "\n",
        "  # Gets all the files in a given folder\n",
        "  files = os.listdir(folder_p)\n",
        "\n",
        "  # If folder is not empty\n",
        "  if files:\n",
        "    # i now acts as the file index in the folder\n",
        "    for i in range(len(files)):\n",
        "      print(\"Processing file:\", files[i])\n",
        "\n",
        "      try:\n",
        "        # Country-wise\n",
        "        print(\"Running handle_problematic_pdf (country) on\", files[i])\n",
        "        start_page = 1\n",
        "        dfs_page = handle_problematic_pdf(folder_p, i, start_page)\n",
        "\n",
        "        print(\"Returned output from handle_problematic_pdf\")\n",
        "\n",
        "        country_df = dfs_page[0]\n",
        "        last_page = dfs_page[1]\n",
        "\n",
        "        # Add a time stamp column (to the leftmost column)\n",
        "        temp_file_name = files[i].split('.')\n",
        "        timestamp_val = temp_file_name[0]\n",
        "\n",
        "        if i == 0:\n",
        "          timestamp_col = [\"\", \"\", \"\"]\n",
        "          for _ in range(country_df.shape[0] - 3):\n",
        "            timestamp_col.append(timestamp_val)\n",
        "          #print(len(timestamp_col))\n",
        "          #print(len(country_df))\n",
        "          country_df.insert(loc=0, column='Timestamp', value=timestamp_col)\n",
        "        else:\n",
        "          country_df.insert(loc=0, column='Timestamp', value=timestamp_val)\n",
        "\n",
        "        # If not the first file, delete the header rows (first three rows)\n",
        "        if i > 0:\n",
        "          country_df = country_df.iloc[3:]\n",
        "\n",
        "        country_dfs.append(country_df)\n",
        "\n",
        "        start_page = last_page + 1\n",
        "\n",
        "        # District-wise\n",
        "        print(\"Running handle_problematic_pdf (district) on\", files[i])\n",
        "        dfs_page = handle_problematic_pdf(folder_p, i, start_page)\n",
        "        district_df = dfs_page[0]\n",
        "\n",
        "        # Add a time stamp column (to the leftmost column)\n",
        "        if i == 0:\n",
        "          timestamp_col = [\"\", \"\", \"\"]\n",
        "          for _ in range(district_df.shape[0] - 3):\n",
        "            timestamp_col.append(timestamp_val)\n",
        "          #print(len(timestamp_col))\n",
        "          #print(len(country_df))\n",
        "          district_df.insert(loc=0, column='Timestamp', value=timestamp_col)\n",
        "        else:\n",
        "          district_df.insert(loc=0, column='Timestamp', value=timestamp_val)\n",
        "\n",
        "        # If not the first file, delete the header rows (first three rows)\n",
        "        if i > 0:\n",
        "          district_df = district_df.iloc[3:]\n",
        "\n",
        "        district_dfs.append(district_df)\n",
        "      except:\n",
        "        print(\"Error occured on file:\", files[i])\n",
        "\n",
        "  # Append files\n",
        "  final_countrywise_df = pd.concat(country_dfs, ignore_index=True)\n",
        "  final_districtwise_df = pd.concat(district_dfs, ignore_index=True)\n",
        "\n",
        "  # Export file to csv\n",
        "  export_file_to_csv(final_countrywise_df, \"countrywise\")\n",
        "  export_file_to_csv(final_districtwise_df, \"districtwise\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4YmQnlPLecVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "4EhcfF7ZRlKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/PDF_Text_Extraction_Project/Approval_PDFs'\n",
        "#folder_path = '/content/drive/My Drive/PDF_Text_Extraction_Project/TestPdf'\n",
        "#folder_path = '/content/drive/My Drive/PDF_Text_Extraction_Project/Problematic_PDFS'\n",
        "\n",
        "test = get_approval_PDFs(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jIT-PVZhuOTT",
        "outputId": "6b4340a9-49b1-45b7-bf56-85ba145e3a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tabula.backend:Failed to import jpype dependencies. Fallback to subprocess.\n",
            "WARNING:tabula.backend:No module named 'jpype'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: 2025_05_14.pdf\n",
            "Running handle_problematic_pdf (country) on 2025_05_14.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "more than one page: 2 pages\n",
            "Dataframes collected: 2\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (89, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "for loop finished running\n",
            "first row is not data, column headers!\n",
            "calculating total row, length of dfs is 2\n",
            "more than one page\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2025_05_14.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is misaligned\n",
            "(80, 23)\n",
            "calculating total row, length of dfs is 1\n",
            "just one page\n",
            "calculate_total_row() finished\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Processing file: 2025_06_14.pdf\n",
            "Running handle_problematic_pdf (country) on 2025_06_14.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "more than one page: 2 pages\n",
            "Dataframes collected: 2\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (89, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "for loop finished running\n",
            "first row is not data, column headers!\n",
            "calculating total row, length of dfs is 2\n",
            "more than one page\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2025_06_14.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is misaligned\n",
            "(80, 23)\n",
            "calculating total row, length of dfs is 1\n",
            "just one page\n",
            "calculate_total_row() finished\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Processing file: 2025_10_17.pdf\n",
            "Running handle_problematic_pdf (country) on 2025_10_17.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "more than one page: 2 pages\n",
            "Dataframes collected: 2\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (101, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "for loop finished running\n",
            "first row is not data, column headers!\n",
            "calculating total row, length of dfs is 2\n",
            "more than one page\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2025_10_17.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is misaligned\n",
            "(80, 23)\n",
            "calculating total row, length of dfs is 1\n",
            "just one page\n",
            "calculate_total_row() finished\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Processing file: 2025-07-16.pdf\n",
            "Running handle_problematic_pdf (country) on 2025-07-16.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "more than one page: 2 pages\n",
            "Dataframes collected: 2\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (89, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "for loop finished running\n",
            "first row is not data, column headers!\n",
            "calculating total row, length of dfs is 2\n",
            "more than one page\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2025-07-16.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is perfectly normal\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Processing file: 2025-08-16.pdf\n",
            "Running handle_problematic_pdf (country) on 2025-08-16.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "more than one page: 2 pages\n",
            "Dataframes collected: 2\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (92, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "for loop finished running\n",
            "first row is not data, column headers!\n",
            "calculating total row, length of dfs is 2\n",
            "more than one page\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2025-08-16.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is misaligned\n",
            "(80, 23)\n",
            "calculating total row, length of dfs is 1\n",
            "just one page\n",
            "calculate_total_row() finished\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Processing file: 2025-09-16.pdf\n",
            "Running handle_problematic_pdf (country) on 2025-09-16.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (101, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is perfectly normal\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2025-09-16.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is misaligned\n",
            "(80, 23)\n",
            "calculating total row, length of dfs is 1\n",
            "just one page\n",
            "calculate_total_row() finished\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Processing file: 2025-11-16.pdf\n",
            "Running handle_problematic_pdf (country) on 2025-11-16.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "more than one page: 2 pages\n",
            "Dataframes collected: 2\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (104, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "for loop finished running\n",
            "first row is not data, column headers!\n",
            "calculating total row, length of dfs is 2\n",
            "more than one page\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2025-11-16.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is misaligned\n",
            "(80, 23)\n",
            "calculating total row, length of dfs is 1\n",
            "just one page\n",
            "calculate_total_row() finished\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Processing file: 2025-12-15.pdf\n",
            "Running handle_problematic_pdf (country) on 2025-12-15.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "more than one page: 2 pages\n",
            "Dataframes collected: 2\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (101, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "for loop finished running\n",
            "first row is not data, column headers!\n",
            "calculating total row, length of dfs is 2\n",
            "more than one page\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2025-12-15.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is misaligned\n",
            "(80, 23)\n",
            "calculating total row, length of dfs is 1\n",
            "just one page\n",
            "calculate_total_row() finished\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Processing file: 2026-01-14.pdf\n",
            "Running handle_problematic_pdf (country) on 2026-01-14.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "more than one page: 2 pages\n",
            "Dataframes collected: 2\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (98, 23)\n",
            "['Recruiting Agency', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "for loop finished running\n",
            "first row is not data, column headers!\n",
            "calculating total row, length of dfs is 2\n",
            "more than one page\n",
            "handle_problematic_pdf() has finished running\n",
            "Returned output from handle_problematic_pdf\n",
            "Running handle_problematic_pdf (district) on 2026-01-14.pdf\n",
            "handle_problematic_pdf() has started\n",
            "blind_find_last_page() ran successfully\n",
            "only one page\n",
            "Running get_first_row()\n",
            "Running get_second_row()\n",
            "Dataframe size: (80, 23)\n",
            "['Recruiting', 'Individual-New', 'G-to-G', 'Individual-ReEntry', 'Legalization', 'Total with ReEntry', 'Total without ReEntry']\n",
            "Length of second_row_list: 23\n",
            "last row is misaligned\n",
            "(80, 23)\n",
            "calculating total row, length of dfs is 1\n",
            "just one page\n",
            "calculate_total_row() finished\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "handle_problematic_pdf() has finished running\n",
            "Running export_file_to_csv()\n",
            "Running export_file_to_csv()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Departure/Arrival Form PDFs:**"
      ],
      "metadata": {
        "id": "JV2ao3bDTBeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets the last page number of the departure/arrival form\n",
        "# Uses the PyPDF2 library which stores number of pages by default\n",
        "def get_DA_last_page_num(file):\n",
        "\n",
        "  my_file = open(file, 'rb')\n",
        "  pdfReader = PyPDF2.PdfReader(file)\n",
        "  totalPages = len(pdfReader.pages)\n",
        "\n",
        "  last_page_num = totalPages\n",
        "  #print(last_page_num)\n",
        "  return last_page_num\n"
      ],
      "metadata": {
        "id": "W4DKiA2MqDUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracts tables from each page as a pandas dataframe\n",
        "# Uses get_DA_last_page_num to determine the last page number\n",
        "# returns the list of the dataframes (each element is each page's table)\n",
        "def extract_DA_forms(file):\n",
        "\n",
        "  first_page = 1\n",
        "  last_page = get_DA_last_page_num(file)\n",
        "\n",
        "  dfs = tabula.read_pdf(file, lattice=True, pages=f'{first_page}-{last_page}', silent=True)\n",
        "\n",
        "  return dfs"
      ],
      "metadata": {
        "id": "iB0z0dsTWyKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If normal table extraction not working, try different setting: stream\n",
        "def extract_DA_forms_stream(file):\n",
        "\n",
        "  first_page = 1\n",
        "  last_page = get_DA_last_page_num(file)\n",
        "\n",
        "  dfs = tabula.read_pdf(file, stream=True, pages=f'{first_page}-{last_page}', silent=True)\n",
        "\n",
        "  return dfs\n"
      ],
      "metadata": {
        "id": "LrhXf7_1zF00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets the first row\n",
        "# Hardcodes the values\n",
        "def get_DA_first_row(df):\n",
        "\n",
        "  first_row_list = [\"\", \"\", \"Arrival\", \"Arrival\", \"Arrival\", \"Arrival\", \"Departure\", \"Departure\", \"Departure\", \"Departure\"]\n",
        "\n",
        "  first_row_df = pd.DataFrame([first_row_list], columns=df.columns)\n",
        "\n",
        "  return first_row_df"
      ],
      "metadata": {
        "id": "0tvk683GYGK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets the second row\n",
        "# Hard codes the values\n",
        "def get_DA_second_row(df):\n",
        "\n",
        "  second_row_list = [\"S.N.\", \"Country\", \"F\", \"M\", \"Unverified\", \"Total\", \"F\", \"M\", \"Unverified\", \"Total\"]\n",
        "\n",
        "  second_row_df = pd.DataFrame([second_row_list], columns=df.columns)\n",
        "\n",
        "  return second_row_df"
      ],
      "metadata": {
        "id": "63qJPP2AbB02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removes completely empty columns and returns the modified dataframe\n",
        "def remove_empty_columns(df):\n",
        "  print(\"called remove_empty_columns()\")\n",
        "\n",
        "  df_cleaned = df.dropna(axis=1, how='all')\n",
        "\n",
        "  return df_cleaned"
      ],
      "metadata": {
        "id": "WcdSv4f5dDhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_missing_total_col(df):\n",
        "  print(\"called add_missing_total_col()\")\n",
        "\n",
        "  total_column = []\n",
        "\n",
        "  for i in range(0, df.shape[0]):\n",
        "    try:\n",
        "      col1 = int(df.iloc[i, 6])\n",
        "      col2 = int(df.iloc[i, 7])\n",
        "      col3 = int(df.iloc[i, 8])\n",
        "      #print(col1, col2, col3)\n",
        "      total_val = col1 + col2 + col3\n",
        "      #print(total_val)\n",
        "      total_column.append(total_val)\n",
        "    except:\n",
        "      print(\"could not add values across row\", i)\n",
        "      total_column.append(0)\n",
        "\n",
        "  #print(len(total_column))\n",
        "\n",
        "  #new_column = pd.DataFrame(total_column)\n",
        "\n",
        "  #df.insert(9, \"totalcol\", total_column)\n",
        "  #print(len(df))\n",
        "  #print(len(total_column))\n",
        "  #df[\"totalcol\"] = total_column\n",
        "  df.insert(loc=len(df.columns), column=\"totalcol\", value=total_column)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "gvq6YlwviMxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given a list of dataframes, remove header rows and keep only numeric rows\n",
        "def prune_DA_dfs(dfs):\n",
        "\n",
        "  print(\"calling prune_DA_dfs()\")\n",
        "\n",
        "  integer_regex = '[0-9]+' # Regular expression for integers\n",
        "\n",
        "  pattern = r'(?i)total\\s+for[eign]+ers?'\n",
        "  foreigner_regex = re.compile(pattern, re.IGNORECASE)\n",
        "\n",
        "  pruned_dfs = []\n",
        "\n",
        "  # Loops through each page except the last\n",
        "  # Uses regular expression to check for a header row\n",
        "  # Modifies accordingly and resets the column names to avoid append complications\n",
        "  # adds it to a list to be appended\n",
        "  for i in range(len(dfs)-2):\n",
        "    df = dfs[i]\n",
        "    row_0 = df.iloc[0, 0] # First row, first column\n",
        "\n",
        "    # Converting data to string type to allow use of regular expressions\n",
        "    if hasattr(row_0, 'decode'):\n",
        "      row_0 = row_0.decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "      row_0 = str(row_0)\n",
        "    try:\n",
        "      matched_regex = re.search(integer_regex, row_0)\n",
        "    except:\n",
        "      print(\"could not use regular expressions in prune_DA_dfs()\")\n",
        "\n",
        "    # First row is data, extract the whole thing\n",
        "    if matched_regex:\n",
        "      new_df = df\n",
        "    # First row is a header row, extract everything except it\n",
        "    else:\n",
        "      new_df = df[1:]\n",
        "\n",
        "    new_df.columns = range(len(new_df.columns))\n",
        "    pruned_dfs.append(new_df)\n",
        "\n",
        "  ##### Handling second last page #######\n",
        "  df = dfs[-2]\n",
        "  row_0 = df.iloc[0, 0] # First row, first column\n",
        "\n",
        "  # Converting data to string type to allow use of regular expressions\n",
        "  if hasattr(row_0, 'decode'):\n",
        "    row_0 = row_0.decode('utf-8', errors='ignore')\n",
        "  else:\n",
        "    row_0 = str(row_0)\n",
        "  try:\n",
        "    matched_regex = re.search(integer_regex, row_0)\n",
        "  except:\n",
        "    print(\"could not use regular expressions in prune_DA_dfs() - first row\")\n",
        "\n",
        "  print(\"handling last page\")\n",
        "  # First row is a data row\n",
        "  if matched_regex:\n",
        "    print(\"first row is a data row\")\n",
        "    new_df = df\n",
        "  # First row is a header row, extract everything except it\n",
        "  else:\n",
        "    print(\"first row is not a data row\")\n",
        "    new_df = df[1:]\n",
        "\n",
        "  # Check if there is a 'total foreigner row' (in the second last row, first column or last row, first column)\n",
        "  if new_df.shape[0] >= 2:\n",
        "    total_foreigner_row = new_df.iloc[-2, 0]\n",
        "    total_foreigner_row2 = new_df.iloc[-1, 0]\n",
        "    #print(total_foreigner_row)\n",
        "\n",
        "    # Converting data to string type to allow use of regular expressions\n",
        "    if hasattr(total_foreigner_row, 'decode'):\n",
        "      total_foreigner_row = total_foreigner_row.decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "      total_foreigner_row = str(total_foreigner_row)\n",
        "    try:\n",
        "      matched_regex_for = re.search(foreigner_regex, total_foreigner_row)\n",
        "    except:\n",
        "      print(\"could not use regular expressions in prune_DA_dfs() - total foreigners row\")\n",
        "\n",
        "    if hasattr(total_foreigner_row2, 'decode'):\n",
        "      total_foreigner_row2 = total_foreigner_row2.decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "      total_foreigner_row2 = str(total_foreigner_row2)\n",
        "    try:\n",
        "      matched_regex_for2 = re.search(foreigner_regex, total_foreigner_row2)\n",
        "    except:\n",
        "      print(\"could not use regular expressions in prune_DA_dfs() - total foreigners row\")\n",
        "\n",
        "    print(\"made it before checking for total foreigners row\")\n",
        "    # If there is a total foreigner row, remove it:\n",
        "    if matched_regex_for:\n",
        "      new_df = new_df.drop(new_df.index[-2])\n",
        "      print(\"dropped the total foreigner row in the second last row\")\n",
        "    elif matched_regex_for2:\n",
        "      new_df = new_df.drop(new_df.index[-1])\n",
        "      print(\"dropped the total foreigner row in the last row\")\n",
        "\n",
        "  new_df.columns = range(len(new_df.columns))\n",
        "  pruned_dfs.append(new_df)\n",
        "\n",
        "  ##### Handling the last page #######\n",
        "  # Do not grab the last row (will manually calculate ourselves)\n",
        "  df = dfs[-1]\n",
        "  row_0 = df.iloc[0, 0] # First row, first column\n",
        "\n",
        "\n",
        "  # Converting data to string type to allow use of regular expressions\n",
        "  if hasattr(row_0, 'decode'):\n",
        "    row_0 = row_0.decode('utf-8', errors='ignore')\n",
        "  else:\n",
        "    row_0 = str(row_0)\n",
        "  try:\n",
        "    matched_regex = re.search(integer_regex, row_0)\n",
        "  except:\n",
        "    print(\"could not use regular expressions in prune_DA_dfs() - first row\")\n",
        "\n",
        "  print(\"handling last page\")\n",
        "  # First row is a data row, extract the whole thing except the last row\n",
        "  if matched_regex:\n",
        "    print(\"first row is a data row\")\n",
        "    new_df = df[:-1]\n",
        "  # First row is a header row, extract everything except it and the last row\n",
        "  else:\n",
        "    print(\"first row is not a data row\")\n",
        "    new_df = df[1:-1]\n",
        "\n",
        "  # Check if there is a 'total foreigner row' (in the second last row, first column)\n",
        "  if new_df.shape[0] >= 2:\n",
        "    total_foreigner_row = new_df.iloc[-2, 0]\n",
        "    #print(total_foreigner_row)\n",
        "\n",
        "    # Converting data to string type to allow use of regular expressions\n",
        "    if hasattr(total_foreigner_row, 'decode'):\n",
        "      total_foreigner_row = total_foreigner_row.decode('utf-8', errors='ignore')\n",
        "    else:\n",
        "      total_foreigner_row = str(total_foreigner_row)\n",
        "    try:\n",
        "      matched_regex_for = re.search(foreigner_regex, total_foreigner_row)\n",
        "    except:\n",
        "      print(\"could not use regular expressions in prune_DA_dfs() - total foreigners row\")\n",
        "\n",
        "    print(\"made it before checking for total foreigners row\")\n",
        "    # If there is a total foreigner row, remove it:\n",
        "    if matched_regex_for:\n",
        "      new_df = new_df.drop(new_df.index[-2])\n",
        "      print(\"dropped the total foreigner row\")\n",
        "\n",
        "  print(\"made it past checking for total foreigners row\")\n",
        "\n",
        "  new_df.columns = range(len(new_df.columns))\n",
        "  pruned_dfs.append(new_df)\n",
        "\n",
        "  print(\"prune_last_page() has finished running\")\n",
        "  return pruned_dfs\n",
        "\n"
      ],
      "metadata": {
        "id": "KUmeE9Xd42B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_DA_total(dfs):\n",
        "  print(\"calling calculate_DA_total()\")\n",
        "\n",
        "  # Concatenate the pages together to calculate the sum (total row)\n",
        "\n",
        "  temp_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  last_row_list = [\"\", \"Total\"]\n",
        "\n",
        "  # Now calculate the sum:\n",
        "  for i in range(len(temp_df.columns)):\n",
        "    # Third column or beyond (first column is id, second is 'total)\n",
        "    if i >= 2:\n",
        "      col_numeric = pd.to_numeric(temp_df.iloc[:, i], errors='coerce')\n",
        "      col_sum = col_numeric.sum()\n",
        "      floored_col_sum = np.floor(col_sum)\n",
        "      rounded_col_sum = int(floored_col_sum)\n",
        "      last_row_list.append(rounded_col_sum)\n",
        "\n",
        "  # Convert list to a pandas dataframe\n",
        "  some_df = dfs[0]\n",
        "  last_row_df = pd.DataFrame([last_row_list], columns=range(len(some_df.columns)))\n",
        "\n",
        "  print(last_row_df)\n",
        "  return last_row_df\n"
      ],
      "metadata": {
        "id": "ZBXJ_lcQnQHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give a dataframe that has 5 columns\n",
        "# Reconstruct the data frame to have 10 columns\n",
        "# Filling in the missing columns with '.' (for compatible use with STATA)\n",
        "def handle_5_col_form(df):\n",
        "  print(\"called handle_5_col_form()\", df.shape[1])\n",
        "\n",
        "  header_row_df = pd.DataFrame([df.columns.tolist()], columns=df.columns)\n",
        "  df_combined = pd.concat([header_row_df, df], ignore_index=True)\n",
        "\n",
        "  df_combined.insert(loc=2, column='Male', value = \".\")\n",
        "  df_combined.insert(loc=3, column='Female', value = \".\")\n",
        "  df_combined.insert(loc=4, column='Other', value = \".\")\n",
        "\n",
        "  df_combined.insert(loc=6, column='Male2', value = \".\")\n",
        "  df_combined.insert(loc=7, column='Female2', value = \".\")\n",
        "  df_combined.insert(loc=8, column='Other2', value = \".\")\n",
        "\n",
        "  # Drop the last column\n",
        "  df_combined = df_combined.drop(columns=df_combined.columns[-1])\n",
        "\n",
        "  return df_combined\n"
      ],
      "metadata": {
        "id": "tl8u7Zhzk1U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runocr(file):\n",
        "    \"\"\"Run OCR on a PDF file, replace it and rename with OCR_ prefix\"\"\"\n",
        "\n",
        "    # Extract directory and filename\n",
        "    directory = os.path.dirname(file)\n",
        "    original_filename = os.path.basename(file)\n",
        "\n",
        "    # Create new filename with OCR_ prefix\n",
        "    new_filename = \"OCR_\" + original_filename\n",
        "    new_file_path = os.path.join(directory, new_filename)\n",
        "\n",
        "    print(f\"Processing: {original_filename}\")\n",
        "    print(f\"Will rename to: {new_filename}\")\n",
        "\n",
        "    # Run OCR to temporary file first\n",
        "    temp_file = \"temp_ocr_output.pdf\"\n",
        "    result = subprocess.run(\n",
        "        ['ocrmypdf', '--force-ocr', file, temp_file],\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        # Remove original file\n",
        "        os.remove(file)\n",
        "        # Rename temporary file to new name\n",
        "        shutil.move(temp_file, new_file_path)\n",
        "        print(f\" OCR successful! Renamed to: {new_filename}\")\n",
        "\n",
        "        # Open and return the renamed file\n",
        "        return_file = fitz.open(new_file_path)\n",
        "        return return_file\n",
        "    else:\n",
        "        print(\" OCR failed! Return code:\", result.returncode)\n",
        "        if result.stderr:\n",
        "            print(\"Error:\", result.stderr)\n",
        "        # Clean up temporary file if it exists\n",
        "        if os.path.exists(temp_file):\n",
        "            os.remove(temp_file)\n",
        "        return None"
      ],
      "metadata": {
        "id": "iBhRIdNh1ePW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_DA_dfs(folder_path):\n",
        "\n",
        "  print(\"calling get_DA_dfs()\")\n",
        "\n",
        "  DA_forms = []\n",
        "  failed_files = []\n",
        "\n",
        "  # Gets all the files in a given folder\n",
        "  files = os.listdir(folder_path)\n",
        "\n",
        "  # If folder is not empty\n",
        "  if files:\n",
        "    # i now acts as the file index in the folder\n",
        "    for i in range(len(files)):\n",
        "      print(\"Processing file:\", files[i])\n",
        "\n",
        "      try:\n",
        "        append_list = []\n",
        "\n",
        "        file = os.path.join(folder_path, files[i])\n",
        "        print(\"in try statement working on:\", file)\n",
        "\n",
        "        extracted = extract_DA_forms(file)\n",
        "\n",
        "        print(\"extracted successfully\")\n",
        "\n",
        "        my_dfs = []\n",
        "\n",
        "        for df in extracted:\n",
        "          new_df = remove_empty_columns(df)\n",
        "          if new_df.shape[1] == 9:\n",
        "            fixed_df = add_missing_total_col(new_df)\n",
        "          elif new_df.shape[1] == 5:\n",
        "            fixed_df = handle_5_col_form(new_df)\n",
        "          else:\n",
        "            fixed_df = new_df\n",
        "          my_dfs.append(fixed_df)\n",
        "\n",
        "        first_row = get_DA_first_row(my_dfs[0])\n",
        "        second_row = get_DA_second_row(my_dfs[0])\n",
        "\n",
        "        append_list.append(first_row)\n",
        "        append_list.append(second_row)\n",
        "\n",
        "        pruned = prune_DA_dfs(my_dfs)\n",
        "\n",
        "        concat_df = pd.concat(pruned, ignore_index=True)\n",
        "        append_list.append(concat_df)\n",
        "\n",
        "        total_row = calculate_DA_total(pruned)\n",
        "        append_list.append(total_row)\n",
        "\n",
        "        print(\"made it before resetting column names\")\n",
        "\n",
        "        for df in append_list:\n",
        "          df.columns = range(len(df.columns))\n",
        "\n",
        "        concat_df = pd.concat(append_list, ignore_index=True)\n",
        "\n",
        "        print(\"made it before adding time stamp\")\n",
        "\n",
        "        # Add a time stamp column (to the leftmost column)\n",
        "        temp_file_name = files[i].split('.')\n",
        "        timestamp_val = temp_file_name[0]\n",
        "\n",
        "        if i == 0:\n",
        "          print(\"first page, need to fix timestamp\")\n",
        "          timestamp_col = [\"\", \"\"]\n",
        "          for _ in range(concat_df.shape[0] - 2):\n",
        "            timestamp_col.append(timestamp_val)\n",
        "          print(len(timestamp_col))\n",
        "          print(len(concat_df))\n",
        "          concat_df.insert(loc=0, column='Timestamp', value=timestamp_col)\n",
        "        else:\n",
        "          concat_df.insert(loc=0, column='Timestamp', value=timestamp_val)\n",
        "\n",
        "        print(\"made it after inserting time stamp \")\n",
        "\n",
        "        # If not the first file, delete the header rows (first two rows)\n",
        "        if i > 0:\n",
        "          concat_df = concat_df.iloc[2:]\n",
        "\n",
        "        DA_forms.append(concat_df)\n",
        "\n",
        "        print(\"file done\")\n",
        "\n",
        "      except:\n",
        "        print(\"Error occured on file:\", files[i])\n",
        "        failed_files.append(files[i])\n",
        "\n",
        "  # Append files\n",
        "  final_DA_df = pd.concat(DA_forms, ignore_index=True)\n",
        "\n",
        "  # Export file to csv\n",
        "  export_file_to_csv(final_DA_df, \"Arrival_Departure\")\n",
        "\n",
        "  print(\"Failed files:\", failed_files)\n"
      ],
      "metadata": {
        "id": "AQs7170c5Mwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "6EnyeJ8VWOa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Official test\n",
        "folder_path = '/content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs'\n",
        "\n",
        "get_DA_dfs(folder_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B5-AVF4yiAIR",
        "outputId": "545a8d12-9306-49ed-86f8-b517cf2cebcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tabula.backend:Failed to import jpype dependencies. Fallback to subprocess.\n",
            "WARNING:tabula.backend:No module named 'jpype'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "calling get_DA_dfs()\n",
            "Processing file: 2018_04.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2018_04.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2       3     4       5      6       7     8       9\n",
            "0    Total  55762  128113  2765  186701  65876  143608  1724  211208\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "first page, need to fix timestamp\n",
            "119\n",
            "119\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2025_07.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2025_07.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  119247  60716  49  180012  145495  64925  55  210475\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2025_06.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2025_06.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  119429  60519  68  180016  146682  67838  67  214587\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2025_05.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2025_05.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  128928  65771  52  194751  162145  88534  57  250736\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2025_04.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2025_04.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  147477  84523  64  232064  158618  95385  40  254043\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2025_03.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2025_03.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  148853  87706  53  236612  156172  97366  51  253589\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2025_02.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2025_02.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  136299  76102  63  212464  135294  78218  40  213552\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2025_01.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2025_01.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  140806  69538  54  210398  135466  71344  45  206855\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2024_12.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_12.pdf\n",
            "extracted successfully\n",
            "Error occured on file: 2024_12.pdf\n",
            "Processing file: 2024_11.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_11.pdf\n",
            "extracted successfully\n",
            "Error occured on file: 2024_11.pdf\n",
            "Processing file: 2024_09.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_09.pdf\n",
            "extracted successfully\n",
            "Error occured on file: 2024_09.pdf\n",
            "Processing file: 2024_08.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_08.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  118663  57699  36  176398  137028  74855  38  211921\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2024_07.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_07.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  116368  57899  45  174312  137512  65562  52  203115\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2024_06.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_06.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  119296  57867  74  177237  138010  67256  54  205320\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2024_05.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_05.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  125917  65232  57  191206  180341  87922  37  268300\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2024_04.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_04.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  141062  78163  36  219261  162492  92327  30  254849\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2024_02.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_02.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  139157  74026  44  213227  147667  77392  34  225093\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2024_03.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_03.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  153880  88527  59  242466  167447  93475  51  260973\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2024_01.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2024_01.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  137557  67366  42  204965  152047  71894  42  223983\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_12.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_12.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1        2       3    4        5        6       7    8        9\n",
            "0    Total  1507942  769925  484  2278354  1716328  870388  617  2586810\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_11.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_11.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  148374  88816  69  237260  155490  93330  45  248865\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_10.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_10.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "Error occured on file: 2023_10.pdf\n",
            "Processing file: 2023_09.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_09.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  130212  64450  46  194708  130373  67105  41  197519\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_08.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_08.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  104757  51566  34  156357  135011  68912  44  203922\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_07.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_07.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4       5       6      7   8       9\n",
            "0    Total  97574  48192  25  145791  130149  60680  26  190855\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_06.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_06.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "Error occured on file: 2023_06.pdf\n",
            "Processing file: 2023_05.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_05.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  110993  56628  57  167678  152095  75547  50  227692\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_04.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_04.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  123638  66624  37  190299  145207  76657  28  221892\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_03.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_03.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  131488  70033  29  201552  155328  75716  29  231073\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_02.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_02.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  119006  58829  23  177858  130559  61098  17  191674\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2023_01.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2023_01.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  119451  51266  23  170740  136645  55228  20  191893\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_12.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_12.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  109625  50808  21  160455  153652  67719  34  221373\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_11.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_11.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  111974  54901  23  166900  159822  72716  23  232553\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_10.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_10.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  130507  68579  20  199107  123267  63616  18  186901\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_09.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_09.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  129964  50284  14  180262  128656  48468  19  177134\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_08.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_08.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4       5       6      7   8       9\n",
            "0    Total  86702  34944  11  121657  125759  47961  15  173735\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_07.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_07.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4       5       6      7   8       9\n",
            "0    Total  84593  36711  17  121321  120074  48339  18  168431\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_06.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_06.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "could not add values across row 0\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "called remove_empty_columns()\n",
            "called add_missing_total_col()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4       5       6      7   8       9\n",
            "0    Total  84217  37516  16  121749  123077  49673  25  172775\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_05.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_05.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4       5       6      7   8       9\n",
            "0    Total  87660  39997  20  127677  117846  57199  21  175066\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_04.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_04.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3   4       5       6      7   8       9\n",
            "0    Total  106953  45054  16  152023  110437  50206  20  160663\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_03.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_03.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4       5      6      7   8       9\n",
            "0    Total  90893  31820  26  122739  97143  35426  22  132591\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_02.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_02.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4      5      6      7  8      9\n",
            "0    Total  66645  19472  14  86131  75036  22664  6  97706\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2022_01.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2022_01.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4      5       6      7   8       9\n",
            "0    Total  70326  19162  11  89499  100351  23594  11  123956\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_11.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_11.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4      5      6      7   8       9\n",
            "0    Total  71082  20836  21  91939  97656  24329  28  122013\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_09.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_09.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4      5      6      7   8      9\n",
            "0    Total  58549  11787  23  70359  68388  12727  28  81143\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_08.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_08.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2     3   4      5      6      7   8      9\n",
            "0    Total  40475  8394  11  48880  44998  10168  10  55176\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_07.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_07.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2     3  4      5      6     7  8      9\n",
            "0    Total  23448  4741  4  28193  20163  4866  2  25031\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_06.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_06.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1     2     3  4      5     6     7  8      9\n",
            "0    Total  8782  1913  2  10697  9509  3711  7  13227\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_05.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_05.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2     3  4      5      6     7   8      9\n",
            "0    Total  10175  2197  2  12374  17296  5639  16  22951\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_04.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_04.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "Error occured on file: 2021_04.pdf\n",
            "Processing file: 2021_03.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_03.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4      5      6      7   8      9\n",
            "0    Total  57510  13718  15  71243  46714  11855  12  58581\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_02.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_02.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3   4      5      6     7   8      9\n",
            "0    Total  46460  11067  15  57542  35178  8951  14  44143\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2021_01.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2021_01.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2     3   4      5      6     7   8      9\n",
            "0    Total  46384  9741  16  56141  37599  9628  11  47238\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2020_11.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_11.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2     3  4      5      6     7  8      9\n",
            "0    Total  29949  5773  3  35725  21681  5028  3  26712\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2020_10.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_10.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2     3  4      5      6     7  8      9\n",
            "0    Total  36559  7146  3  43708  18627  5047  1  23675\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2020_09.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_09.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "Error occured on file: 2020_09.pdf\n",
            "Processing file: 2020_08.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_08.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "Error occured on file: 2020_08.pdf\n",
            "Processing file: 2020_07.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_07.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2     3  4      5     6     7  8     9\n",
            "0    Total  22479  2242  5  24726  4473  1976  7  6456\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2020_06.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_06.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2     3  4      5     6     7  8     9\n",
            "0    Total  10560  3836  4  14400  3991  3013  9  7013\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2020_05.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_05.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1    2   3  4    5     6     7  8     9\n",
            "0    Total  267  63  0  330  1983  1376  2  3361\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2020_04.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_04.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "Error occured on file: 2020_04.pdf\n",
            "Processing file: 2020_03.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_03.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2      3    4      5      6      7     8       9\n",
            "0    Total  68164  30754  918  99836  64702  36588  2203  103493\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2020_02.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_02.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1       2      3  4       5       6      7  8       9\n",
            "0    Total  124957  57177  0  186608  116933  53172  0  177344\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2020_01.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_01.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row in the last row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2       3     4       5      6       7      8       9\n",
            "0    Total  51915  117781  8801  178497  56731  123613  12426  192770\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2018_11.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2018_11.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2       3     4       5      6       7     8       9\n",
            "0    Total  81119  140222  2739  224080  93018  154012  2332  249362\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Processing file: 2018_05.pdf\n",
            "in try statement working on: /content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2018_05.pdf\n",
            "extracted successfully\n",
            "called remove_empty_columns()\n",
            "called remove_empty_columns()\n",
            "calling prune_DA_dfs()\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "handling last page\n",
            "first row is not a data row\n",
            "made it before checking for total foreigners row\n",
            "dropped the total foreigner row\n",
            "made it past checking for total foreigners row\n",
            "prune_last_page() has finished running\n",
            "calling calculate_DA_total()\n",
            "  0      1      2       3     4       5      6       7     8       9\n",
            "0    Total  41681  103560  3008  148252  55228  132576  1910  189714\n",
            "made it before resetting column names\n",
            "made it before adding time stamp\n",
            "made it after inserting time stamp \n",
            "file done\n",
            "Running export_file_to_csv()\n",
            "Failed files: ['2024_12.pdf', '2024_11.pdf', '2024_09.pdf', '2023_10.pdf', '2023_06.pdf', '2021_04.pdf', '2020_09.pdf', '2020_08.pdf', '2020_04.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#folder_path = '/content/drive/My Drive/PDF_Text_Extraction_Project/Arrival_Departure_PDFs/2020_01.pdf'\n",
        "\n",
        "folder_path = '/content/drive/My Drive/PDF_Text_Extraction_Project/Problematic_PDFS/OCR_Copy of 2024_09.pdf'\n",
        "\n",
        "test_dfs = extract_DA_forms(folder_path)\n",
        "print(len(test_dfs))\n",
        "\n",
        "for i in range(len(test_dfs)):\n",
        "  export_file_to_csv(test_dfs[i], f\"test_2024_09{i}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHgroCP6ip2W",
        "outputId": "3bd5ef8b-4e7c-42da-a9e0-86d5ad146bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    }
  ]
}